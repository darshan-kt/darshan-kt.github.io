<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Development of a Low-Cost Multipurpose Autonomous Navigation Robot</title>
  <!-- Link your main stylesheet -->
  <link rel="stylesheet" href="style.css">
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
  <style>
    /* Dark theme styling */
    body {
      background-color: #121212;
      font-family: 'Poppins', sans-serif;
      margin: 0;
      padding: 0;
      color: #fff;
    }
    .report-container {
      max-width: 800px;
      margin: 2rem auto;
      padding: 2rem;
      background: #000;
      box-shadow: 0 0 10px rgba(0,0,0,0.8);
      line-height: 1.6;
    }
    .report-container h1,
    .report-container h2,
    .report-container h3 {
      color: #1db954;
      text-align: left;
      margin-bottom: 1rem;
    }
    .report-container p,
    .report-container li,
    .report-container pre {
      text-align: justify;
      margin-bottom: 1rem;
    }
    .report-container ul,
    .report-container ol {
      margin-left: 1.5rem;
      margin-bottom: 1rem;
    }
    .report-container figure {
      margin: 1.5rem 0;
      text-align: center;
    }
    .report-container figcaption {
      font-size: 0.9rem;
      color: #aaa;
      margin-top: 0.5rem;
    }
    .video-container {
      text-align: center;
      margin-bottom: 2rem;
    }
    .video-container a {
      display: inline-block;
      text-decoration: none;
    }
    .video-container img {
      max-width: 100%;
      border-radius: 8px;
    }
    .image-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-bottom: 2rem;
    }
    .image-grid img {
      width: 100%;
      border-radius: 8px;
    }
    .media-link {
      text-align: center;
      margin-top: 2rem;
    }
    .media-link a {
      display: inline-block;
      padding: 0.5rem 1rem;
      background: #1db954;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      font-size: 1.2rem;
      transition: background 0.3s ease;
    }
    .media-link a:hover {
      background: #13a04a;
    }
  </style>
</head>
<body>
  <!-- Navigation Bar -->
  <nav>
    <div class="container">
      <a href="index.html" class="logo">Jerin Peter</a>
      <ul class="nav-links">
        <li><a href="index.html#projects">Projects</a></li>
        <li><a href="index.html#experience">Experience</a></li>
        <li><a href="index.html#publications">Publications</a></li>
        <li><a href="index.html#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <!-- Report Container -->
  <div class="report-container">
    <h1>Development of a Low-Cost Multipurpose Autonomous Navigation Robot</h1> 
    
    <!-- Demo Video as YouTube Thumbnail -->
    <div class="video-container">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/sJpIB1qDBU4?si=nepu9VAb021fT-kS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>
    
    <!-- Abstract -->
    <h2>Abstract</h2>
    <p>
      The COVID-19 pandemic has accelerated the need for contactless solutions.
      This paper presents the design and development of a low-cost multipurpose autonomous navigation robot.
      The proposed system utilizes a Lidar sensor in conjunction with a Pi camera to perform Simultaneous Localization and Mapping (SLAM),
      enabling the robot to autonomously navigate dynamic environments.
      Additionally, the robot is equipped with capabilities for object detection, person following, and real-time surveillance,
      making it suitable for UV sanitization, food and medicine delivery, and teleoperation.
    </p>
    
    <!-- Introduction -->
    <h2>Introduction</h2>
    <p>
      Modern autonomous robots face high initial costs, limiting their widespread use.
      Advances in open-source platforms like ROS have paved the way for developing low-cost robotic systems.
      This work addresses the challenge of mapping unknown environments through the integration of affordable sensors
      and robust SLAM algorithms.
      By leveraging a Lidar sensor and a low-cost Pi camera, the system achieves reliable mapping and navigation,
      making it a viable solution for various applications during and beyond the pandemic.
    </p>
    
    <!-- Methodology -->
    <h2>Methodology</h2>
    <p>
      The development process began with detailed design and simulation studies in Fusion360.
      The CAD model was then converted to a URDF format and refined through 3D printing using PLA material.
      Key hardware components include:
    </p>
    <ul>
      <li>
        <strong>Main Chassis:</strong> Four disk structures (120 mm diameter, 3 mm thickness) form the primary body.
      </li>
      <li>
        <strong>Bottom Deck:</strong> Houses DC motors with encoders and a motor driver for movement.
      </li>
      <li>
        <strong>Upper Deck:</strong> Contains low-level control equipment (Teensy 3.6 microcontroller) and an MPU-6050 IMU,
        used for pose estimation.
      </li>
      <li>
        <strong>Sensor Suite:</strong> A wide-angle Pi camera provides real-time video for surveillance, and the Lidar sensor
        facilitates precise mapping.
      </li>
    </ul>
    
    <!-- Image Grid for Hardware/Prototype -->
    <div class="image-grid">
      <img src="assets/images/projects/low_cost_robot/robot1.jpg" alt="CAD Model">
      <img src="assets/images/projects/low_cost_robot/robot2.jpg" alt="3D Printed Prototype">
      <img src="assets/images/projects/low_cost_robot/robot3.jpg" alt="Assembly View">
      <img src="assets/images/projects/low_cost_robot/robot4.jpg" alt="Final Prototype">
      <img src="assets/images/projects/low_cost_robot/robot5.jpg" alt="Final Prototype">
      <img src="assets/images/projects/low_cost_robot/robot6.jpg" alt="Final Prototype">


    </div>
    
    <!-- Results and Discussion -->
    <h2>Results and Discussion</h2>
    <p>
      Simulation studies in Gazebo and subsequent real-world testing confirmed that the robot can autonomously map its environment
      and navigate to predefined goal locations. The integration of Lidar and the Pi camera provided robust data for the SLAM algorithms,
      enabling accurate localization even in dynamic settings.
      Experimental results demonstrated that the system can reliably perform tasks such as obstacle avoidance, object recognition,
      and person following.
    </p>
    
    <!-- Conclusion -->
    <h2>Conclusion</h2>
    <p>
      The developed low-cost multipurpose autonomous navigation robot offers a practical solution for contactless operations.
      With its affordable sensor suite and robust SLAM implementation, the robot can be deployed for UV sanitization,
      delivery of food and medicine, and teleoperated surveillance.
      Future enhancements will focus on refining the object detection algorithms and integrating additional sensors
      to further improve navigation accuracy and operational reliability.
    </p>
    
    <!-- Future Scope -->
    <h2>Future Scope</h2>
    <ul>
      <li>Integration with advanced ROS-based path planning and localization modules.</li>
      <li>Implementation of enhanced object recognition and person following using machine learning frameworks.</li>
      <li>Expansion of the sensor suite to include additional environmental monitoring tools.</li>
      <li>Scaling the prototype for larger, commercial-grade applications.</li>
    </ul>
    

    
    <!-- References -->
    <h2>References</h2>
    <ol>
      <li>Thomas, M.J. et al., "Dynamic Modeling and Control of Autonomous Robots," Journal of Robotics, 2021.</li>
      <li>Labb√©, M. and Michaud, F., "RTAB-Map: Real-Time Appearance Based Mapping," Journal of Field Robotics, 2019.</li>
      <li>Dudek, G. and Jenkin, M., "Differential Drive Robots," Cambridge University Press, 2010.</li>
      <li>Additional references are detailed in the full paper.</li>
    </ol>
    
    <!-- View Full Report Button -->
    <div class="media-link">
      <a href="PublishedieeepaperAugust2022.pdf" target="_blank">
        <i class="fas fa-file-pdf" style="font-size: 2rem; vertical-align: middle; margin-right: 0.5rem;"></i> View Full Report PDF
      </a>
    </div>
  </div>
  
  <!-- Footer -->
  <footer style="text-align: center; padding: 1rem 0; background-color: #000; color: #1db954;">
    <p>&copy; 2025 Jerin Peter. All rights reserved.</p>
  </footer>
</body>
</html>
